

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>4.3. Memory Management &mdash; Numba 0.49.0dev0+636.ga4807f5d8 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/numba-blue-icon-rgb.svg"/>
  
  
  
    <link rel="canonical" href="http://numba.pydata.org/numba-doc/latest/index.htmlcuda-reference/memory.html"/>
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5. Numba for AMD ROC GPUs" href="../roc/index.html" />
    <link rel="prev" title="4.2. CUDA Kernel API" href="kernel.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Numba
          

          
            
            <img src="../_static/numba-blue-icon-rgb.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.49
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../user/index.html">1. User Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">2. Reference Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/index.html">3. Numba for CUDA GPUs</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">4. CUDA Python Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="host.html">4.1. CUDA Host API</a></li>
<li class="toctree-l2"><a class="reference internal" href="kernel.html">4.2. CUDA Kernel API</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">4.3. Memory Management</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#device-objects">4.3.1. Device Objects</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../roc/index.html">5. Numba for AMD ROC GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extending/index.html">6. Extending Numba</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer/index.html">7. Developer Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../proposals/index.html">8. Numba Enhancement Proposals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">9. Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release-notes.html">10. Release Notes</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Numba</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content style-external-links">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">4. CUDA Python Reference</a> &raquo;</li>
        
      <li>4.3. Memory Management</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/cuda-reference/memory.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="memory-management">
<h1>4.3. Memory Management<a class="headerlink" href="#memory-management" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="numba.cuda.to_device">
<code class="sig-prename descclassname">numba.cuda.</code><code class="sig-name descname">to_device</code><span class="sig-paren">(</span><em class="sig-param">obj</em>, <em class="sig-param">stream=0</em>, <em class="sig-param">copy=True</em>, <em class="sig-param">to=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.to_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Allocate and transfer a numpy ndarray or structured scalar to the device.</p>
<p>To copy host-&gt;device a numpy array:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">d_ary</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">ary</span><span class="p">)</span>
</pre></div>
</div>
<p>To enqueue the transfer to a stream:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">stream</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">stream</span><span class="p">()</span>
<span class="n">d_ary</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">ary</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">)</span>
</pre></div>
</div>
<p>The resulting <code class="docutils literal notranslate"><span class="pre">d_ary</span></code> is a <code class="docutils literal notranslate"><span class="pre">DeviceNDArray</span></code>.</p>
<p>To copy device-&gt;host:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hary</span> <span class="o">=</span> <span class="n">d_ary</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">()</span>
</pre></div>
</div>
<p>To copy device-&gt;host to an existing array:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ary</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">d_ary</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">d_ary</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">d_ary</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">(</span><span class="n">ary</span><span class="p">)</span>
</pre></div>
</div>
<p>To enqueue the transfer to a stream:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hary</span> <span class="o">=</span> <span class="n">d_ary</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="n">stream</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.device_array">
<code class="sig-prename descclassname">numba.cuda.</code><code class="sig-name descname">device_array</code><span class="sig-paren">(</span><em class="sig-param">shape</em>, <em class="sig-param">dtype=np.float</em>, <em class="sig-param">strides=None</em>, <em class="sig-param">order='C'</em>, <em class="sig-param">stream=0</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.device_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Allocate an empty device ndarray. Similar to <a class="reference internal" href="../developer/autogen_numpy_listing.html#numpy.empty" title="numpy.empty"><code class="xref py py-meth docutils literal notranslate"><span class="pre">numpy.empty()</span></code></a>.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.device_array_like">
<code class="sig-prename descclassname">numba.cuda.</code><code class="sig-name descname">device_array_like</code><span class="sig-paren">(</span><em class="sig-param">ary</em>, <em class="sig-param">stream=0</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.device_array_like" title="Permalink to this definition">¶</a></dt>
<dd><p>Call cuda.devicearray() with information from the array.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.pinned_array">
<code class="sig-prename descclassname">numba.cuda.</code><code class="sig-name descname">pinned_array</code><span class="sig-paren">(</span><em class="sig-param">shape</em>, <em class="sig-param">dtype=np.float</em>, <em class="sig-param">strides=None</em>, <em class="sig-param">order='C'</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.pinned_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Allocate a np.ndarray with a buffer that is pinned (pagelocked).
Similar to np.empty().</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.mapped_array">
<code class="sig-prename descclassname">numba.cuda.</code><code class="sig-name descname">mapped_array</code><span class="sig-paren">(</span><em class="sig-param">shape</em>, <em class="sig-param">dtype=np.float</em>, <em class="sig-param">strides=None</em>, <em class="sig-param">order='C'</em>, <em class="sig-param">stream=0</em>, <em class="sig-param">portable=False</em>, <em class="sig-param">wc=False</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.mapped_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Allocate a mapped ndarray with a buffer that is pinned and mapped on
to the device. Similar to np.empty()</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>portable</strong> – a boolean flag to allow the allocated device memory to be
usable in multiple devices.</p></li>
<li><p><strong>wc</strong> – a boolean flag to enable writecombined allocation which is faster
to write by the host and to read by the device, but slower to
write by the host and slower to write by the device.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.pinned">
<code class="sig-prename descclassname">numba.cuda.</code><code class="sig-name descname">pinned</code><span class="sig-paren">(</span><em class="sig-param">*arylist</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.pinned" title="Permalink to this definition">¶</a></dt>
<dd><p>A context manager for temporary pinning a sequence of host ndarrays.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.mapped">
<code class="sig-prename descclassname">numba.cuda.</code><code class="sig-name descname">mapped</code><span class="sig-paren">(</span><em class="sig-param">*arylist</em>, <em class="sig-param">**kws</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.mapped" title="Permalink to this definition">¶</a></dt>
<dd><p>A context manager for temporarily mapping a sequence of host ndarrays.</p>
</dd></dl>

<div class="section" id="device-objects">
<h2>4.3.1. Device Objects<a class="headerlink" href="#device-objects" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="numba.cuda.cudadrv.devicearray.DeviceNDArray">
<em class="property">class </em><code class="sig-prename descclassname">numba.cuda.cudadrv.devicearray.</code><code class="sig-name descname">DeviceNDArray</code><span class="sig-paren">(</span><em class="sig-param">shape</em>, <em class="sig-param">strides</em>, <em class="sig-param">dtype</em>, <em class="sig-param">stream=0</em>, <em class="sig-param">writeback=None</em>, <em class="sig-param">gpu_data=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.devicearray.DeviceNDArray" title="Permalink to this definition">¶</a></dt>
<dd><p>An on-GPU array type</p>
<dl class="method">
<dt id="numba.cuda.cudadrv.devicearray.DeviceNDArray.copy_to_device">
<code class="sig-name descname">copy_to_device</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">ary</em>, <em class="sig-param">stream=0</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.devicearray.DeviceNDArray.copy_to_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy <cite>ary</cite> to <cite>self</cite>.</p>
<p>If <cite>ary</cite> is a CUDA memory, perform a device-to-device transfer.
Otherwise, perform a a host-to-device transfer.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.devicearray.DeviceNDArray.copy_to_host">
<code class="sig-name descname">copy_to_host</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">ary=None</em>, <em class="sig-param">stream=0</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.devicearray.DeviceNDArray.copy_to_host" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy <code class="docutils literal notranslate"><span class="pre">self</span></code> to <code class="docutils literal notranslate"><span class="pre">ary</span></code> or create a new Numpy ndarray
if <code class="docutils literal notranslate"><span class="pre">ary</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
<p>If a CUDA <code class="docutils literal notranslate"><span class="pre">stream</span></code> is given, then the transfer will be made
asynchronously as part as the given stream.  Otherwise, the transfer is
synchronous: the function returns after the copy is finished.</p>
<p>Always returns the host array.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">cuda</span>

<span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">d_arr</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>

<span class="n">my_kernel</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">](</span><span class="n">d_arr</span><span class="p">)</span>

<span class="n">result_array</span> <span class="o">=</span> <span class="n">d_arr</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.devicearray.DeviceNDArray.is_c_contiguous">
<code class="sig-name descname">is_c_contiguous</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.devicearray.DeviceNDArray.is_c_contiguous" title="Permalink to this definition">¶</a></dt>
<dd><p>Return true if the array is C-contiguous.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.devicearray.DeviceNDArray.is_f_contiguous">
<code class="sig-name descname">is_f_contiguous</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.devicearray.DeviceNDArray.is_f_contiguous" title="Permalink to this definition">¶</a></dt>
<dd><p>Return true if the array is Fortran-contiguous.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.devicearray.DeviceNDArray.ravel">
<code class="sig-name descname">ravel</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">order='C'</em>, <em class="sig-param">stream=0</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.devicearray.DeviceNDArray.ravel" title="Permalink to this definition">¶</a></dt>
<dd><p>Flatten the array without changing its contents, similar to
<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.ravel.html#numpy.ndarray.ravel" title="(in NumPy v1.17)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">numpy.ndarray.ravel()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.devicearray.DeviceNDArray.reshape">
<code class="sig-name descname">reshape</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">*newshape</em>, <em class="sig-param">**kws</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.devicearray.DeviceNDArray.reshape" title="Permalink to this definition">¶</a></dt>
<dd><p>Reshape the array without changing its contents, similarly to
<a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.reshape.html#numpy.ndarray.reshape" title="(in NumPy v1.17)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">numpy.ndarray.reshape()</span></code></a>. Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">d_arr</span> <span class="o">=</span> <span class="n">d_arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.devicearray.DeviceNDArray.split">
<code class="sig-name descname">split</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">section</em>, <em class="sig-param">stream=0</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.devicearray.DeviceNDArray.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Split the array into equal partition of the <cite>section</cite> size.
If the array cannot be equally divided, the last section will be
smaller.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="numba.cuda.cudadrv.devicearray.DeviceRecord">
<em class="property">class </em><code class="sig-prename descclassname">numba.cuda.cudadrv.devicearray.</code><code class="sig-name descname">DeviceRecord</code><span class="sig-paren">(</span><em class="sig-param">dtype</em>, <em class="sig-param">stream=0</em>, <em class="sig-param">gpu_data=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.devicearray.DeviceRecord" title="Permalink to this definition">¶</a></dt>
<dd><p>An on-GPU record type</p>
<dl class="method">
<dt id="numba.cuda.cudadrv.devicearray.DeviceRecord.copy_to_device">
<code class="sig-name descname">copy_to_device</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">ary</em>, <em class="sig-param">stream=0</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.devicearray.DeviceRecord.copy_to_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy <cite>ary</cite> to <cite>self</cite>.</p>
<p>If <cite>ary</cite> is a CUDA memory, perform a device-to-device transfer.
Otherwise, perform a a host-to-device transfer.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.devicearray.DeviceRecord.copy_to_host">
<code class="sig-name descname">copy_to_host</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">ary=None</em>, <em class="sig-param">stream=0</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.devicearray.DeviceRecord.copy_to_host" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy <code class="docutils literal notranslate"><span class="pre">self</span></code> to <code class="docutils literal notranslate"><span class="pre">ary</span></code> or create a new Numpy ndarray
if <code class="docutils literal notranslate"><span class="pre">ary</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
<p>If a CUDA <code class="docutils literal notranslate"><span class="pre">stream</span></code> is given, then the transfer will be made
asynchronously as part as the given stream.  Otherwise, the transfer is
synchronous: the function returns after the copy is finished.</p>
<p>Always returns the host array.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">cuda</span>

<span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">d_arr</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>

<span class="n">my_kernel</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">](</span><span class="n">d_arr</span><span class="p">)</span>

<span class="n">result_array</span> <span class="o">=</span> <span class="n">d_arr</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="numba.cuda.cudadrv.devicearray.MappedNDArray">
<em class="property">class </em><code class="sig-prename descclassname">numba.cuda.cudadrv.devicearray.</code><code class="sig-name descname">MappedNDArray</code><span class="sig-paren">(</span><em class="sig-param">shape</em>, <em class="sig-param">strides</em>, <em class="sig-param">dtype</em>, <em class="sig-param">stream=0</em>, <em class="sig-param">writeback=None</em>, <em class="sig-param">gpu_data=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.devicearray.MappedNDArray" title="Permalink to this definition">¶</a></dt>
<dd><p>A host array that uses CUDA mapped memory.</p>
<dl class="method">
<dt id="numba.cuda.cudadrv.devicearray.MappedNDArray.copy_to_device">
<code class="sig-name descname">copy_to_device</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">ary</em>, <em class="sig-param">stream=0</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.devicearray.MappedNDArray.copy_to_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy <cite>ary</cite> to <cite>self</cite>.</p>
<p>If <cite>ary</cite> is a CUDA memory, perform a device-to-device transfer.
Otherwise, perform a a host-to-device transfer.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.devicearray.MappedNDArray.copy_to_host">
<code class="sig-name descname">copy_to_host</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">ary=None</em>, <em class="sig-param">stream=0</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.devicearray.MappedNDArray.copy_to_host" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy <code class="docutils literal notranslate"><span class="pre">self</span></code> to <code class="docutils literal notranslate"><span class="pre">ary</span></code> or create a new Numpy ndarray
if <code class="docutils literal notranslate"><span class="pre">ary</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
<p>If a CUDA <code class="docutils literal notranslate"><span class="pre">stream</span></code> is given, then the transfer will be made
asynchronously as part as the given stream.  Otherwise, the transfer is
synchronous: the function returns after the copy is finished.</p>
<p>Always returns the host array.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">cuda</span>

<span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">d_arr</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>

<span class="n">my_kernel</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">](</span><span class="n">d_arr</span><span class="p">)</span>

<span class="n">result_array</span> <span class="o">=</span> <span class="n">d_arr</span><span class="o">.</span><span class="n">copy_to_host</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.devicearray.MappedNDArray.split">
<code class="sig-name descname">split</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">section</em>, <em class="sig-param">stream=0</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.devicearray.MappedNDArray.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Split the array into equal partition of the <cite>section</cite> size.
If the array cannot be equally divided, the last section will be
smaller.</p>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../roc/index.html" class="btn btn-neutral float-right" title="5. Numba for AMD ROC GPUs" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="kernel.html" class="btn btn-neutral float-left" title="4.2. CUDA Kernel API" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2012-2020, Anaconda, Inc. and others

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>